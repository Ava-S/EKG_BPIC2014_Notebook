{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-31T15:58:04.128870Z",
     "start_time": "2025-05-31T15:58:04.043417Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from promg.modules.db_management import DBManagement\n",
    "from tabulate import tabulate\n",
    "import yaml\n",
    "\n",
    "from promg import Configuration, DatabaseConnection, Performance, SemanticHeader, DatasetDescriptions, OcedPg, Query\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.width', 2000)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define the project that you want to do analysis on",
   "id": "53749a6e25cc2172"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:58:04.133081Z",
     "start_time": "2025-05-31T15:58:04.129875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "case_study = 'bpic14'\n",
    "# case_study = 'bpic17'\n",
    "use_sample = False"
   ],
   "id": "fc9da47c43b8414d",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:58:04.158670Z",
     "start_time": "2025-05-31T15:58:04.134086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# retrieve configuration for case_study\n",
    "conf_path = Path(case_study, 'config.yaml')\n",
    "config = yaml.safe_load(open(conf_path))\n",
    "\n",
    "print(f\"These are the credentials that I expect to be set for the database.\")\n",
    "print(f\"db_name: {config[\"db_name\"]}\")\n",
    "print(f\"user: {config[\"user\"]}\")\n",
    "print(f\"uri: {config[\"uri\"]}\")\n",
    "print(f\"password: {config[\"password\"]}\")\n",
    "print(\"----------------------\")\n",
    "print(f\"If you have other credentials, please change them at: {conf_path}\")"
   ],
   "id": "aa3387e167d67135",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the credentials that I expect to be set for the database.\n",
      "db_name: neo4j\n",
      "user: neo4j\n",
      "uri: bolt://localhost:7687\n",
      "password: bpic2014\n",
      "----------------------\n",
      "If you have other credentials, please change them at: bpic14\\config.yaml\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prepare so we can use PromG to execute queries",
   "id": "e8120ab6c716ab32"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:58:04.168258Z",
     "start_time": "2025-05-31T15:58:04.159678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = Configuration.init_conf_with_config_file(conf_path)\n",
    "db_connection = DatabaseConnection.set_up_connection(config=config)"
   ],
   "id": "6a43b12f667191c7",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Start Analysis\n",
    "Make sure the data imported using import_data.ipynb. The imported data is in the schema as defined in the paper"
   ],
   "id": "8de33f54a3ecfdef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analysis Goals\n",
    "We want to repeat the analysis perform in \n",
    "\n",
    "`Klijn, E.L., Mannhardt, F., Fahland, D. (2023). Aggregating Event Knowledge Graphs for Task Analysis. In: Montali, M., Senderovich, A., Weidlich, M. (eds) Process Mining Workshops. ICPM 2022. Lecture Notes in Business Information Processing, vol 468. Springer, Cham. https://doi.org/10.1007/978-3-031-27815-0_36`\n",
    "\n",
    "We want to infer tasks between resources and cases, let's indicate the type of the Resource and the type of the case"
   ],
   "id": "a2e7cf94d6deb4ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:58:04.177439Z",
     "start_time": "2025-05-31T15:58:04.168258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# This needs domain knowledge. All queries below will use these types as parameters\n",
    "resource_type = None\n",
    "case_type = None\n",
    "batch_sizes = None\n",
    "if case_study == \"bpic17\":\n",
    "    resource_type = \"Resource\"\n",
    "    case_type = \"CaseAWO\"\n",
    "    batch_sizes = {\n",
    "        \"CaseAWO\": 5000,\n",
    "        \"Resource\": 10,\n",
    "    }\n",
    "elif case_study == \"bpic14\":\n",
    "    resource_type = \"Resource\"\n",
    "    case_type = \"Interaction\"\n",
    "    batch_sizes = {\n",
    "        \"Interaction\": 10_000,\n",
    "        \"Resource\": 10,\n",
    "    }\n",
    "object_types = [resource_type, case_type]\n",
    "object_types"
   ],
   "id": "5ae25a9f6857575e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Resource', 'Interaction']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "First, we have to discover the DF relations for the resources and the case. For this we can use a generic, parameterized query."
   ],
   "id": "f46e887962af8d48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:58:15.392021Z",
     "start_time": "2025-05-31T15:58:04.178443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Discover DF for the objects in our data model\n",
    "\n",
    "# to ensure we don't overload the database, we will run the query for each object_type separately\n",
    "# furthermore, we have a small number of resources (149) with many events, and many cases (31509) with a low number of events\n",
    "# to accommodate for this, we will adapt the batch size accordingly\n",
    "\n",
    "df_instance_query_str = '''\n",
    "    CALL apoc.periodic.iterate('\n",
    "        MATCH (o) - [:INSTANCE_OF] -> (ot:ObjectType {objectType: $object_type})\n",
    "        RETURN o, ot\n",
    "    ','\n",
    "        MATCH (e:Event) - [e2o_instance] -> (o) // we remove the check on the event type level for performance increase, and we have no roles so check is redundant\n",
    "        WITH o.id as oId, ot.objectType as oType, e order by e.timestamp, id(e)\n",
    "        WITH oId, oType, collect(e) as events\n",
    "        WITH oId, oType, events\n",
    "        UNWIND range(0, size(events)-2) AS i\n",
    "            WITH oId, oType, events[i] AS e1, events[i+1] AS e2\n",
    "            MERGE (e1) - [df:DF {objectType:oType, id:oId}] -> (e2)',\n",
    "        {batchSize:$batch_size, parallel: true, params:{object_type:$object_type}})\n",
    "'''\n",
    "\n",
    "for object_type in object_types:\n",
    "    print(f\"Discovering df for object_type: {object_type}\")\n",
    "\n",
    "    df_instance_query = Query(\n",
    "        query_str=df_instance_query_str,\n",
    "        parameters={\n",
    "            \"object_type\": object_type,\n",
    "            \"batch_size\": batch_sizes[object_type]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    results = db_connection.exec_query(df_instance_query)\n",
    "    print(results)  #make sure there are 0 failed batches, if there are failed batches, then you should probably increase the storage of your db\n"
   ],
   "id": "3ba46e75fe853869",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovering df for object_type: Resource\n",
      "[{'batches': 25, 'total': 242, 'timeTaken': 7, 'committedOperations': 242, 'failedOperations': 0, 'failedBatches': 0, 'retries': 0, 'errorMessages': {}, 'batch': {'total': 25, 'errors': {}, 'committed': 25, 'failed': 0}, 'operations': {'total': 242, 'errors': {}, 'committed': 242, 'failed': 0}, 'wasTerminated': False, 'failedParams': {}, 'updateStatistics': {'relationshipsDeleted': 0, 'relationshipsCreated': 466495, 'nodesDeleted': 0, 'nodesCreated': 0, 'labelsRemoved': 0, 'labelsAdded': 0, 'propertiesSet': 932990}}]\n",
      "Discovering df for object_type: Interaction\n",
      "[{'batches': 15, 'total': 147173, 'timeTaken': 1, 'committedOperations': 147173, 'failedOperations': 0, 'failedBatches': 0, 'retries': 0, 'errorMessages': {}, 'batch': {'total': 15, 'errors': {}, 'committed': 15, 'failed': 0}, 'operations': {'total': 147173, 'errors': {}, 'committed': 147173, 'failed': 0}, 'wasTerminated': False, 'failedParams': {}, 'updateStatistics': {'relationshipsDeleted': 0, 'relationshipsCreated': 0, 'nodesDeleted': 0, 'nodesCreated': 0, 'labelsRemoved': 0, 'labelsAdded': 0, 'propertiesSet': 0}}]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Build tasks",
   "id": "8ad625dae87429d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:58:20.783893Z",
     "start_time": "2025-05-31T15:58:15.397027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# First, we identify tasks\n",
    "\n",
    "identify_tasks = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "    \"MATCH (e1:Event)-[r_df:DF {objectType: $resource_type}]->(e2:Event)\n",
    "     WHERE (e1)-[:DF {objectType: $case_type}]->(e2)\n",
    "     AND date(e1.timestamp) = date(e2.timestamp) // ensure to carry task instances over days\n",
    "     RETURN e1,e2\",\n",
    "     \"WITH e1,e2\n",
    "     MERGE (e1)-[:DF_JOINT]->(e2)\",\n",
    "     {batchSize:$batch_size, parallel: true, params: {resource_type:$resource_type, case_type:$case_type}})\n",
    "'''\n",
    "\n",
    "identify_tasks_query = Query(\n",
    "    query_str=identify_tasks,\n",
    "    parameters={\n",
    "        \"resource_type\": resource_type,\n",
    "        \"case_type\": case_type\n",
    "    }\n",
    ")\n",
    "\n",
    "db_connection.exec_query(identify_tasks_query)\n"
   ],
   "id": "92cc47da6bf5cdbe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'batches': 23,\n",
       "  'total': 228144,\n",
       "  'timeTaken': 5,\n",
       "  'committedOperations': 228144,\n",
       "  'failedOperations': 0,\n",
       "  'failedBatches': 0,\n",
       "  'retries': 0,\n",
       "  'errorMessages': {},\n",
       "  'batch': {'total': 23, 'errors': {}, 'committed': 23, 'failed': 0},\n",
       "  'operations': {'total': 228144,\n",
       "   'errors': {},\n",
       "   'committed': 228144,\n",
       "   'failed': 0},\n",
       "  'wasTerminated': False,\n",
       "  'failedParams': {},\n",
       "  'updateStatistics': {'relationshipsDeleted': 0,\n",
       "   'relationshipsCreated': 228144,\n",
       "   'nodesDeleted': 0,\n",
       "   'nodesCreated': 0,\n",
       "   'labelsRemoved': 0,\n",
       "   'labelsAdded': 0,\n",
       "   'propertiesSet': 0}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:00.389564Z",
     "start_time": "2025-05-31T15:58:20.785898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we create task instances and also their type\n",
    "create_task_instances = '''\n",
    "    CALL apoc.periodic.iterate(\n",
    "    \"\n",
    "        CALL {\n",
    "            // find complete path between e1 and e2 (full task instance) consisting of at least two events\n",
    "            MATCH (e1:Event)-[df_joint:DF_JOINT]->()\n",
    "                WHERE NOT ()-[:DF_JOINT]->(e1) // e1 is starting event as it has no preceding event\n",
    "                        \n",
    "            MATCH ()-[:DF_JOINT]->(e2:Event) \n",
    "                WHERE NOT (e2)-[:DF_JOINT]->() // e2 is ending event as it has no succeeding event\n",
    "            \n",
    "            MATCH p=(e1)-[:DF_JOINT*]->(e2) // find path between e1 and e2\n",
    "            RETURN p, e1, e2\n",
    "                      \n",
    "        UNION\n",
    "            // find single task instances consisting of one event\n",
    "            MATCH (et:EventType) <- [:INSTANCE_OF] - (e:Event)\n",
    "            WHERE (e)-[]->()-[:INSTANCE_OF] -> (:ObjectType {objectType:$resource_type}) <- [] - (et) //check e is performed by resource type\n",
    "                AND NOT ()-[:DF_JOINT]->(e) // e has no preceding event\n",
    "                AND NOT (e)-[:DF_JOINT]->() // e has no succeeding event\n",
    "            MATCH p=(e) \n",
    "            RETURN p, e AS e1, e AS e2\n",
    "        }\n",
    "        RETURN \n",
    "            [event IN nodes(p) | head([(event)-[:INSTANCE_OF]->(et:EventType) | et.eventType])] AS variant,\n",
    "            nodes(p) AS events, \n",
    "            e1.timestamp AS start_time, e1.id as start_id, \n",
    "            e2.timestamp AS end_time, e2.id as end_id\n",
    "    \",\n",
    "    \"\n",
    "        WITH variant, events, start_time, start_id, end_time, end_id\n",
    "            MERGE (etStart: EventType {eventType: 'START' + variant  , agg: 'Task'})\n",
    "            MERGE (etEnd: EventType {eventType: 'END' + variant , agg: 'Task'})\n",
    "            MERGE (etStart) - [:BELONGS_TO] -> (etEnd)\n",
    "            MERGE (tiStart:Event {timestamp: start_time, id:'Ti-Start-'+start_id+'-'+end_id}) - [:INSTANCE_OF] -> (etStart)\n",
    "            MERGE (tiEnd:Event {timestamp: end_time, id:'TI-End-'+start_id+'-'+end_id}) - [:INSTANCE_OF] -> (etEnd)\n",
    "            MERGE (tiStart) - [:BELONGS_TO] -> (tiEnd)\n",
    "        WITH tiStart, tiEnd, etStart, etEnd, events\n",
    "        UNWIND events AS e\n",
    "            MATCH (e) - [:INSTANCE_OF]->(et)\n",
    "            CREATE (tiStart) -[:CONTAINS]-> (e)\n",
    "            CREATE (tiEnd) -[:CONTAINS]-> (e)\n",
    "            \n",
    "            MERGE (etStart) - [:CONTAINS] -> (et)\n",
    "            MERGE (etEnd) - [:CONTAINS] -> (et)\n",
    "    \",\n",
    "    {batchSize:$batch_size, params:{resource_type:$resource_type, case_type:$case_type}})\n",
    "'''\n",
    "\n",
    "create_task_instances_query = Query(\n",
    "    query_str=create_task_instances,\n",
    "    parameters={\n",
    "        \"resource_type\": resource_type,\n",
    "        \"case_type\": case_type\n",
    "    }\n",
    ")\n",
    "\n",
    "db_connection.exec_query(create_task_instances_query)"
   ],
   "id": "eefd570950597173",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'batches': 24,\n",
       "  'total': 238593,\n",
       "  'timeTaken': 39,\n",
       "  'committedOperations': 238593,\n",
       "  'failedOperations': 0,\n",
       "  'failedBatches': 0,\n",
       "  'retries': 0,\n",
       "  'errorMessages': {},\n",
       "  'batch': {'total': 24, 'errors': {}, 'committed': 24, 'failed': 0},\n",
       "  'operations': {'total': 238593,\n",
       "   'errors': {},\n",
       "   'committed': 238593,\n",
       "   'failed': 0},\n",
       "  'wasTerminated': False,\n",
       "  'failedParams': {},\n",
       "  'updateStatistics': {'relationshipsDeleted': 0,\n",
       "   'relationshipsCreated': 1722985,\n",
       "   'nodesDeleted': 0,\n",
       "   'nodesCreated': 493542,\n",
       "   'labelsRemoved': 0,\n",
       "   'labelsAdded': 493542,\n",
       "   'propertiesSet': 987084}}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:01.097769Z",
     "start_time": "2025-05-31T15:59:00.390663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "add_count_to_event_types = '''\n",
    "    MATCH (e:Event) - [:INSTANCE_OF]->(et:EventType)\n",
    "    WITH et, count(e) as count\n",
    "    SET et.count = count\n",
    "'''\n",
    "\n",
    "db_connection.exec_query(add_count_to_event_types)"
   ],
   "id": "9c310c9168607b4e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:02.053955Z",
     "start_time": "2025-05-31T15:59:01.098786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we can remove the synchronization dfs we just created\n",
    "delete_sync_df = '''\n",
    "CALL apoc.periodic.iterate(\n",
    "    \"MATCH (:Event)-[df:DF_JOINT]->(:Event)\n",
    "     RETURN df\",\n",
    "     \"DELETE df\",\n",
    "     {batchSize:$batch_size, parallel: True})\n",
    "'''\n",
    "\n",
    "db_connection.exec_query(delete_sync_df)"
   ],
   "id": "cecc96ce867dbe67",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'batches': 23,\n",
       "  'total': 228144,\n",
       "  'timeTaken': 0,\n",
       "  'committedOperations': 228144,\n",
       "  'failedOperations': 0,\n",
       "  'failedBatches': 0,\n",
       "  'retries': 0,\n",
       "  'errorMessages': {},\n",
       "  'batch': {'total': 23, 'errors': {}, 'committed': 23, 'failed': 0},\n",
       "  'operations': {'total': 228144,\n",
       "   'errors': {},\n",
       "   'committed': 228144,\n",
       "   'failed': 0},\n",
       "  'wasTerminated': False,\n",
       "  'failedParams': {},\n",
       "  'updateStatistics': {'relationshipsDeleted': 228144,\n",
       "   'relationshipsCreated': 0,\n",
       "   'nodesDeleted': 0,\n",
       "   'nodesCreated': 0,\n",
       "   'labelsRemoved': 0,\n",
       "   'labelsAdded': 0,\n",
       "   'propertiesSet': 0}}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:22.335584Z",
     "start_time": "2025-05-31T15:59:02.057230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# now we have to ensure that the task instances also observe the corresponding objects\n",
    "# also ensure this is lifted to the type level\n",
    "\n",
    "# takes roughly 2 minutes on bpic14\n",
    "\n",
    "observe_ti_to_objects = '''\n",
    " CALL apoc.periodic.iterate(\n",
    "        \" MATCH (ti:Event) - [:INSTANCE_OF] -> (ti_et:EventType {agg:'Task'}) \n",
    "          MATCH (ti)-[:CONTAINS]->(e:Event)-[e2o]-> (o) - [:INSTANCE_OF] -> (ot:ObjectType)\n",
    "          WHERE ot.objectType IN [$resource_type, $case_type]\n",
    "          RETURN DISTINCT ti, ti_et, o, ot, type(e2o) as e2o_type\",\n",
    "        \"WITH ti, ti_et, o, ot, e2o_type\n",
    "            CALL apoc.create.relationship(ti, e2o_type, {}, o)\n",
    "            YIELD rel as new_e2o\n",
    "            RETURN new_e2o\n",
    "            \",\n",
    "        {batchSize:$batch_size, params: {resource_type:$resource_type, case_type:$case_type}})\n",
    "'''\n",
    "\n",
    "observe_ti_to_objects_query = Query(\n",
    "    query_str=observe_ti_to_objects,\n",
    "    parameters={\n",
    "        \"resource_type\": resource_type,\n",
    "        \"case_type\": case_type\n",
    "    }\n",
    ")\n",
    "\n",
    "db_connection.exec_query(observe_ti_to_objects_query)\n"
   ],
   "id": "526979d6d4e35738",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'batches': 96,\n",
       "  'total': 954372,\n",
       "  'timeTaken': 20,\n",
       "  'committedOperations': 954372,\n",
       "  'failedOperations': 0,\n",
       "  'failedBatches': 0,\n",
       "  'retries': 0,\n",
       "  'errorMessages': {},\n",
       "  'batch': {'total': 96, 'errors': {}, 'committed': 96, 'failed': 0},\n",
       "  'operations': {'total': 954372,\n",
       "   'errors': {},\n",
       "   'committed': 954372,\n",
       "   'failed': 0},\n",
       "  'wasTerminated': False,\n",
       "  'failedParams': {},\n",
       "  'updateStatistics': {'relationshipsDeleted': 0,\n",
       "   'relationshipsCreated': 0,\n",
       "   'nodesDeleted': 0,\n",
       "   'nodesCreated': 0,\n",
       "   'labelsRemoved': 0,\n",
       "   'labelsAdded': 0,\n",
       "   'propertiesSet': 0}}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:30.083462Z",
     "start_time": "2025-05-31T15:59:22.336595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "convert_belongs_to_to_df = '''\n",
    "    MATCH (ti1:Event) - [:INSTANCE_OF] -> (ti_et1:EventType {agg:'Task'})\n",
    "    MATCH (ti2:Event) - [:INSTANCE_OF] -> (ti_et2:EventType {agg:'Task'}) \n",
    "    MATCH (ti1) - [:BELONGS_TO] -> (ti2)\n",
    "    MATCH (ti_et1) - [:BELONGS_TO] -> (ti_et2)\n",
    "    MATCH (ti1)-[:CONTAINS]->(e1:Event)-[e2e:DF]->(e2:Event)<-[:CONTAINS]-(ti2)\n",
    "    WHERE e2e.objectType IN [$resource_type, $case_type] \n",
    "     \n",
    "    MERGE (ti1) - [new_e2e:DF {objectType: e2e.objectType, id: e2e.id, agg:'Task'}] -> (ti2)\n",
    "'''\n",
    "\n",
    "convert_belongs_to_to_df_query = Query(\n",
    "    query_str=convert_belongs_to_to_df,\n",
    "    parameters={\n",
    "        \"resource_type\": resource_type,\n",
    "        \"case_type\": case_type\n",
    "    }\n",
    ")\n",
    "\n",
    "result = db_connection.exec_query(convert_belongs_to_to_df_query)\n",
    "print(tabulate(result))"
   ],
   "id": "cfe148302cc5a9df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:47.892814Z",
     "start_time": "2025-05-31T15:59:30.085469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lift_df_to_task_instances = '''\n",
    "    CALL apoc.periodic.iterate('\n",
    "        MATCH (ti1:Event) - [:INSTANCE_OF] -> (ti_et1:EventType {agg:\"Task\"}) \n",
    "        MATCH (ti2:Event) - [:INSTANCE_OF] -> (ti_et2:EventType {agg:\"Task\"}) \n",
    "        WHERE ti1 <> ti2 \n",
    "            AND (ti_et1) <- [:BELONGS_TO] - (:EventType) //ti_et1 is a end of the task instance\n",
    "            AND (ti_et2) - [:BELONGS_TO] -> (:EventType) //ti_et2 is a start of the task instance\n",
    "        MATCH (ti1)-[:CONTAINS]->(:Event)-[e2e:DF]->(:Event)<-[:CONTAINS]-(ti2)\n",
    "        WHERE e2e.objectType IN [$resource_type, $case_type] \n",
    "        RETURN ti1, e2e, ti2\n",
    "    ','\n",
    "        MERGE (ti1) - [new_e2e:DF {objectType: e2e.objectType, id: e2e.id, agg:\"Task\"}] -> (ti2)\n",
    "    ',{batchSize:$batch_size, params: {resource_type:$resource_type, case_type:$case_type}})\n",
    "    \n",
    "'''\n",
    "\n",
    "lift_df_to_task_instances_query = Query(\n",
    "    query_str=lift_df_to_task_instances,\n",
    "    parameters={\n",
    "        \"resource_type\": resource_type,\n",
    "        \"case_type\": case_type,\n",
    "        \"batch_size\": 5000\n",
    "    }\n",
    ")\n",
    "\n",
    "result = db_connection.exec_query(lift_df_to_task_instances_query)\n",
    "result"
   ],
   "id": "bb785c3bfb1cf30d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'batches': 174,\n",
       "  'total': 865537,\n",
       "  'timeTaken': 17,\n",
       "  'committedOperations': 865537,\n",
       "  'failedOperations': 0,\n",
       "  'failedBatches': 0,\n",
       "  'retries': 0,\n",
       "  'errorMessages': {},\n",
       "  'batch': {'total': 174, 'errors': {}, 'committed': 174, 'failed': 0},\n",
       "  'operations': {'total': 865537,\n",
       "   'errors': {},\n",
       "   'committed': 865537,\n",
       "   'failed': 0},\n",
       "  'wasTerminated': False,\n",
       "  'failedParams': {},\n",
       "  'updateStatistics': {'relationshipsDeleted': 0,\n",
       "   'relationshipsCreated': 685233,\n",
       "   'nodesDeleted': 0,\n",
       "   'nodesCreated': 0,\n",
       "   'labelsRemoved': 0,\n",
       "   'labelsAdded': 0,\n",
       "   'propertiesSet': 2055699}}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:51.309930Z",
     "start_time": "2025-05-31T15:59:47.894819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Query to derive a Multi-Entity DF-Graph by aggregating instance-level DF relationships at the event type level.\n",
    "df_aggregation_query_str = '''\\\n",
    "    CALL apoc.periodic.iterate('\n",
    "        // find all consecutive event types for specific object types\n",
    "        MATCH (e1:Event) - [e2e:DF] -> (e2:Event)\n",
    "        MATCH (e1) - [:INSTANCE_OF] -> (et1:EventType {agg: \"Task\"})\n",
    "        MATCH (e2) - [:INSTANCE_OF] -> (et2:EventType {agg: \"Task\"})\n",
    "    \n",
    "        WITH e2e.objectType as oType, et1, et2, count(e2e) as df_freq // count for each oType, how often we have observed DF between events that are an instance of et1 and et2\n",
    "        WHERE df_freq > $df_threshold\n",
    "        RETURN oType, et1, et2\n",
    "    ','\n",
    "        WITH oType, et1, et2\n",
    "        MERGE (et1) - [:DF {objectType:oType, agg:\"Task\"}] -> (et2)\n",
    "    ', \n",
    "    {batchSize:$batch_size, params:{df_threshold:$df_threshold}})\n",
    "'''\n",
    "\n",
    "df_aggregation_query = Query(\n",
    "    query_str=df_aggregation_query_str,\n",
    "    parameters={\n",
    "        \"df_threshold\": 0\n",
    "    }\n",
    ")\n",
    "\n",
    "results = db_connection.exec_query(df_aggregation_query)\n",
    "print(tabulate(results))"
   ],
   "id": "a8e4f6ec7b9779e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--  ------  -  ------  -  -  -  --  ---------------------------------------------------------  -----------------------------------------------------------------  -----  --  ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "13  122067  3  122067  0  0  0  {}  {'total': 13, 'errors': {}, 'committed': 13, 'failed': 0}  {'total': 122067, 'errors': {}, 'committed': 122067, 'failed': 0}  False  {}  {'relationshipsDeleted': 0, 'relationshipsCreated': 122067, 'nodesDeleted': 0, 'nodesCreated': 0, 'labelsRemoved': 0, 'labelsAdded': 0, 'propertiesSet': 244134}\n",
      "--  ------  -  ------  -  -  -  --  ---------------------------------------------------------  -----------------------------------------------------------------  -----  --  ----------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:51.827735Z",
     "start_time": "2025-05-31T15:59:51.311943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_tasks = '''\n",
    "    MATCH (ti_et:EventType {agg:'Task'}) - [:BELONGS_TO] -> (ti_end)\n",
    "    RETURN count(ti_et) as count\n",
    "'''\n",
    "\n",
    "count_ti = '''\n",
    "    MATCH (ti_et:EventType {agg:'Task'}) <- [:INSTANCE_OF] - (ti_start:Event) - [:BELONGS_TO] -> (ti_end)\n",
    "    RETURN count(ti_start) as count\n",
    "'''\n",
    "\n",
    "num_tasks = db_connection.exec_query(count_tasks)\n",
    "num_tasks_instances = db_connection.exec_query(count_ti)\n",
    "\n",
    "print(f\"In total there are {num_tasks[0]['count']} tasks with {num_tasks_instances[0]['count']} instances.\")"
   ],
   "id": "5b1d55cc2044d901",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total there are 8178 tasks with 238593 instances.\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T15:59:51.835732Z",
     "start_time": "2025-05-31T15:59:51.828755Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d47a775086d976cd",
   "outputs": [],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
